{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8526ae1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[ x ]    \u001b[0m Libraries Imported succesfully.\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored \n",
    "import os\n",
    "import subprocess\n",
    "try:\n",
    "    import time \n",
    "    import json \n",
    "    import requests\n",
    "    print(colored(\"[ x ]    \",\"green\"),\"Libraries Imported succesfully.\")\n",
    "except Exception as e:\n",
    "    print(colored(\"[ x ]   \",\"red\"   ),\"Library Importing failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29452f0",
   "metadata": {},
   "source": [
    "#### Checking if Ollama is ready or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51024f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_URL  =   \"https://localhost:11434/v1/chat/comletions\"\n",
    "MODEL       =   \"deepseek-coder:6.7b\"\n",
    "\n",
    "def check_ollama_ready():\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:11434/api/tags\")\n",
    "        if response.status_code != 200:\n",
    "            print(colored(\"[ x ]\", \"red\"), \"Ollama server not responding\")\n",
    "            return False\n",
    "        if response.status_code == 200:\n",
    "            print(colored(\"[ x ]    \",\"green\"), \"Ollama server running.\")\n",
    "        models = response.json().get('models', [])\n",
    "        model_exists = any(m['name'].startswith(MODEL.split(':')[0]) for m in models)\n",
    "        \n",
    "        if not model_exists:\n",
    "            print(colored(\"[ x ]\", \"red\"), f\"Model {MODEL} not found. Pulling it now...\")\n",
    "            import subprocess\n",
    "            subprocess.run([\"ollama\", \"pull\", MODEL])\n",
    "            print(colored(\"[ âœ“ ]\", \"green\"), \"Model pulled successfully\")\n",
    "        \n",
    "        return True\n",
    "\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(colored(\"[ x ]\", \"red\"), \"Cannot connect to Ollama. Run 'ollama serve'\")\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1206a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[ x ]    \u001b[0m Ollama server running.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_ollama_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bbdf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[ x ]    \u001b[0m Ollama server running.\n",
      "\u001b[36mInteractive Chat Started (type 'exit 0' to quit)\n",
      "\u001b[0m\n",
      "\u001b[31m[ x ]    \u001b[0m ERROR: HTTPSConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /v1/chat/comletions (Caused by SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:1032)')))\n"
     ]
    }
   ],
   "source": [
    "def stream_generate(conversation):\n",
    "    payload = {\n",
    "        \"model\":MODEL,\n",
    "        \"message\": conversation,\n",
    "        \"stream\":True,\n",
    "        \"options\":{\n",
    "            \"temperature\":0.7,\n",
    "            \"num_predict\":500\n",
    "        }\n",
    "    }\n",
    "    full_response = \"\"\n",
    "    \n",
    "    try:\n",
    "        with requests.post(OLLAMA_URL, json=payload, stream=True, timeout=60) as r:\n",
    "            r.raise_for_status()\n",
    "            \n",
    "            print(f\"\\nAssistant:\", end=\" \", flush=True)\n",
    "            for line in r.iter_line():\n",
    "                if not line:\n",
    "                    continue\n",
    "                \n",
    "                line = line.decode(\"utf-8\")\n",
    "                \n",
    "                if line.startswith(\"data: \"):\n",
    "                    line = line[6:]\n",
    "                if line.strip() == \"[DONE]\":\n",
    "                    break \n",
    "                \n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "                    delta = data[\"choices\"][0][\"delta\"]\n",
    "                    if \"content\" in delta:\n",
    "                        token = delta[\"content\"]\n",
    "                        full_response += token \n",
    "                        print(token, end=\"\", flush=True)\n",
    "                        \n",
    "                except json.JSONDecodeError:\n",
    "                    continue \n",
    "            print(\"\\n\")\n",
    "        return full_response\n",
    "    except Exception as e:\n",
    "        print(colored(\"[ x ]    \",\"red\"), f\"ERROR: {e}\")\n",
    "        return \"\" \n",
    "    \n",
    "    \n",
    "def main():\n",
    "    if not check_ollama_ready():\n",
    "        return\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    print(colored(\"Interactive Chat Started (type 'exit 0' to quit)\\n\", \"cyan\"))\n",
    "\n",
    "    conversation = []\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "\n",
    "        if user_input.strip().lower() == \"exit 0\":\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "        conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        response = stream_generate(conversation)\n",
    "\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd494ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genv_vs",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
